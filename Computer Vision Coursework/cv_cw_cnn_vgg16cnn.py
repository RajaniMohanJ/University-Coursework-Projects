# -*- coding: utf-8 -*-
"""CV_CW_CNN_VGG16CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZL-R7NI8zk22Ix5lkmawfklQeiO67PXL

# Computer Vision Coursework Submission (IN3060/INM460)

**Student name, ID and cohort:** Rajani Mohan Janipalli (210049506) - PG

## Training and testing script for baseline CNN and VGG16 CNN models.

**Google Colab Setup**
"""

from google.colab import drive
drive.mount('/content/drive')

## CODING REFERENCE: Code was taken from Lab Tutorial 07 of Computer Vision - IN3060/INM460 module.

"""**Updating Open CV**"""

!pip install opencv-python==4.5.5.64

## CODING REFERENCE: Code was taken from Lab Tutorial 07 of Computer Vision - IN3060/INM460 module.

"""**Check the version open CV**"""

!pip show opencv-python

## CODING REFERENCE: Code was taken from Lab Tutorial 07 of Computer Vision - IN3060/INM460 module.

"""**Assign path to link the folder containing the colab notebook.**"""

import os


GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/Computer Vision Coursework/CW_Folder_PG/Code' 
GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)
print(os.listdir(GOOGLE_DRIVE_PATH))


## CODING REFERENCE: Code was taken from Lab Tutorial 07 of Computer Vision - IN3060/INM460 module.

"""**Assign path to link the folder containing the train dataset.**"""

GOOGLE_DRIVE_PATH_AFTER_MYDRIVE_DS = 'Colab Notebooks/Computer Vision Coursework/CW_Folder_PG/CW_Dataset' 
GOOGLE_DRIVE_PATH_DS = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE_DS)
print(os.listdir(GOOGLE_DRIVE_PATH_DS))


# Code from above cell was modified in the this cell, as the dataset resides in a different folder.

"""**Copy and unzip the dataset directly in colab server.**"""

# Identify path to zipped dataset
CW_zip_path = os.path.join(GOOGLE_DRIVE_PATH_DS, 'CW_Dataset.zip')

# Copy it to Colab
!cp '{CW_zip_path}' .

# Unzip it
!yes|unzip -q CW_Dataset.zip

# Delete zipped version from Colab (not from Drive)
!rm CW_Dataset.zip


## CODING REFERENCE: Code was taken from Lab Tutorial 07 of Computer Vision - IN3060/INM460 module.

"""**Import necessary libraries.**"""

# Commented out IPython magic to ensure Python compatibility.
import cv2
from sklearn.model_selection import train_test_split
from skimage import img_as_ubyte, io, color
from sklearn.cluster import MiniBatchKMeans
from sklearn import svm, metrics
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter

# %matplotlib inline

## CODING REFERENCE: Code was taken from Lab Tutorial 07 of Computer Vision - IN3060/INM460 module.

"""Create a fucntio to import data image names and labels as encoded numbers into a pandas data frame."""

import pandas as pd


def create_imagename_dataframe(path):
    """Create a dataframe of images and labels from selected directories"""
    data_df = pd.DataFrame(columns=["imgname", "label"])
    data_df["imgname"] = [file for file in sorted(os.listdir(os.path.join(path))) if file.endswith('.jpg')]
    label_set = np.loadtxt(os.path.join('labels', 'list_label_{}.txt'.format(path)), dtype='str')
    label_nums = [] # create an empty list to append label numbers.
    for i in range(len(label_set)): # execute a for loop to extract the exact labels from data and append them to a list.
      label_nums.append(label_set[i][1])
    
    # label_names = label_names = ['Suprise' if p == '1' else 'Fear' if p == '2' else 'Disgust' if p == '3' else 'Happiness' if p == '4' else 'Sadness' if p == '5' else 'Anger' if p == '6' else 'Neutral' for p in label_nums]

    data_df["label"] = label_nums

    data_df.to_csv (r'{}_df_csv.csv'.format(path), index = False, header=True)
    
    print('Create datafame with file name {}_df_csv.csv'.format(path))
    
## CODING REFERENCE: Code was taken from Lab Tutorial 07 of Computer Vision - IN3060/INM460 module
## and modified as per the requirement in this task.
## https://tutorial.eyehunts.com/python/python-elif-in-list-comprehension-conditionals-example-code/
## https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc

create_imagename_dataframe('train')

create_imagename_dataframe('test')

"""Create a class to convert pandas to pytorch dataset."""

from torch.utils.data import Dataset
import pandas as pd
import os
from PIL import Image
import torch

class CreateDataset(Dataset):
    def __init__(self, root_dir, annotation_file, transform=None):
        self.root_dir = root_dir
        self.annotations = pd.read_csv(annotation_file)
        self.transform = transform

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        
        img_id = self.annotations.iloc[idx, 0]
        img = Image.open(os.path.join(self.root_dir, img_id))
        y_label = self.annotations.iloc[idx, 1]

        if self.transform is not None:
            img = self.transform(img)

        return (img, y_label)


## CODING REFERENCE
## https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc
## https://pytorch.org/tutorials/recipes/recipes/custom_dataset_transforms_loader.html

"""**Import additional libraries.**"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
# from Model import CNN
# from Dataset import CatsAndDogsDataset
from tqdm import tqdm
device = ("cuda" if torch.cuda.is_available() else "cpu")


## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

"""Create transformation object."""

transform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ]
    )

## CODING REFERENCE
## https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc

"""Create datasets and dataloaders for training and test data."""

train_dataset = CreateDataset("train","train_df_csv.csv",transform=transform)
test_dataset = CreateDataset("test","test_df_csv.csv",transform=transform)
train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=16,num_workers=1)
test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=16,num_workers=1)

## CODING REFERENCE
## https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc

print('Training set size (num images)', len(train_dataset))
print('Testing set size (num images)', len(test_dataset))

## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

dataiter_tr1 = iter(train_loader)
images_tr1, labels_tr1 = dataiter_tr1.next()
print(type(images_tr1))
print(images_tr1.shape)
print(labels_tr1.shape)

## CODING REFERENCE: https://discuss.pytorch.org/t/how-to-find-shape-and-columns-for-dataloader/34901

dataiter_te1 = iter(test_loader)
images_te1, labels_te1 = dataiter_te1.next()
print(type(images_te1))
print(images_te1.shape)
print(labels_te1.shape)

## CODING REFERENCE: https://discuss.pytorch.org/t/how-to-find-shape-and-columns-for-dataloader/34901

print('Training set size (num mini-batches)', len(train_loader))
print('Testing set size (num mini-batches)', len(test_loader))

## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

import torchvision
import torchvision.transforms as transforms

"""Create and use function to display images from dataloaders."""

import matplotlib.pyplot as plt
import numpy as np

# function to show an image
def imagedisplay(img):
    img = img / 2 + 0.5     # Unnormalize: back to range [0, 1] just for showing the images
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))     # Reshape: C, H, W -> H, W, C
    plt.show()


# get some random training images
dataiter_tr2 = iter(train_loader)
images_tr2, labels_tr2 = dataiter_tr2.next()

# show images and print labels
imagedisplay(torchvision.utils.make_grid(images_tr2))
first_labels = [labels_tr2[label].item() for label in labels_tr2]
print('Ground-truth:', first_labels)
print('Label explanation: 1-Surprise, 2-Fear, 3-Disgust, 4-Happiness, 5-Sadness, 6-Anger, 7-Neutral')

## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

"""Create network architechture for baseline CNN model."""

import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 22 * 22, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 8)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), 16 * 22 * 22)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()


## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.
## https://github.com/PacktPublishing/Convolutional-Neural-Network-with-PyTorch/blob/master/cnn.py

"""*Note: The above architecture in terms of number of nodes was obtained after mutiple trial and errors attemps and was the most suitable for the given data.*

Define loss calculation method and optimization configuration for baseline CNN.
"""

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

"""Train baseline CNN."""

import time

t0 = time.time()

for epoch in range(20):  # loop over the training set two times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels_train = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels_train)
        loss.backward()
        optimizer.step()

        # print statistics (loss.item() returns the mean loss in the mini-batch)
        running_loss += loss.item()
        if i % 500 == 499:    # print every 200 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training: total time in seconds =', time.time() - t0)


## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.
## https://github.com/PacktPublishing/Convolutional-Neural-Network-with-PyTorch/blob/master/cnn.py

"""Save the baseline CNN model."""

MODELPATH = 'drive/My Drive/Colab Notebooks/Computer Vision Coursework/CW_Folder_PG/Models/CNN_FER.pt'

torch.save(net.state_dict(), MODELPATH)

dataiter_te2 = iter(test_loader)
images_te2, labels_te2 = dataiter_te2.next()

# show images and print labels
imagedisplay(torchvision.utils.make_grid(images_te2))
testfirst_labels = [labels_te2[label].item() for label in labels_te2]
print('Ground-truth:', testfirst_labels)
print('Label explanation: 1-Surprise, 2-Fear, 3-Disgust, 4-Happiness, 5-Sadness, 6-Anger, 7-Neutral')

## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

"""Test baseline CNN on test data."""

# Estimate average accuracy
correct = 0
total = 0
with torch.no_grad():             # Avoid backprop at test 
    for data in test_loader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        

print(f"Accuracy of the network on the 3068 test images: {100 * correct / total}%")
imagedisplay(torchvision.utils.make_grid(images))
print('Ground-truth:', labels)
print('Ground-truth:', predicted)
print('Label explanation: 1-Surprise, 2-Fear, 3-Disgust, 4-Happiness, 5-Sadness, 6-Anger, 7-Neutral')

## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

"""Label explanation: (taken from Readme file of dataset)

1: Surprise

2: Fear

3: Disgust

4: Happiness

5: Sadness

6: Anger

7: Neutral

Load VGG16 pretrained model and define its loss calculation method and optimization configuration.
"""

from torchvision import models
import torch.optim as optim

vgg16cnn = models.vgg16(pretrained = True)
criterionvgg = nn.CrossEntropyLoss().cuda()
optimizervgg = optim.SGD(vgg16cnn.parameters(), lr=0.001, momentum=0.9)

## CODING REFERENCE:
## Code was taken from Lab Tutorial 09 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

"""Train VGG16 CNN model."""

import time

t0 = time.time()

for epoch in range(15):  # loop over the training set two times

    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        vgg16cnn = vgg16cnn.cuda()
        inputs, labels_train = data

        # zero the parameter gradients
        optimizervgg.zero_grad()

        # forward + backward + optimize
        outputs = vgg16cnn(inputs.cuda())
        loss = criterionvgg(outputs.cuda(), labels_train.cuda())
        loss.backward()
        optimizervgg.step()

        # print statistics (loss.item() returns the mean loss in the mini-batch)
        running_loss += loss.item()
        if i % 500 == 499:    # print every 200 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 500))
            running_loss = 0.0

print('Finished Training: total time in seconds =', time.time() - t0)

## CODING REFERENCE:
## Code was taken from Lab Tutorial 08 of Computer Vision - IN3060/INM460 module and modified as per the requirement in this task.

"""Save VGG16 CNN model."""

VGG16CNN1MODELPATH = 'drive/My Drive/Colab Notebooks/Computer Vision Coursework/CW_Folder_PG/Models/VGG16CNN1_FER.pt'

torch.save(vgg16cnn.state_dict(), VGG16CNN1MODELPATH)

"""Test VGG16 CNN model on test data."""

# Estimate average accuracy
correct = 0
total = 0
with torch.no_grad():             # Avoid backprop at test 
    for data in test_loader:
        vgg16cnn = vgg16cnn.cuda()
        images, labels = data
        outputs = vgg16cnn(images.cuda())
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels.cuda()).sum().item()

print(f"Accuracy of the network on the 3068 test images: {100 * correct / total}%")